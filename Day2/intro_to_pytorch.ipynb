{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to PyTorch**\n",
    "\n",
    "The material in this notebook is based on the [PyTorch documentation](https://pytorch.org/docs/stable/index.html). In the `Tensors` chapter, ChatGPT has helped with a few example code chunks and summarization for broadcasting rules :wink:.\n",
    "\n",
    "As you already know, python has libraries for nearly all tasks. For machine learning, the two most popular ones are [PyTorch](https://pytorch.org/) and [TensorFlow](https://www.tensorflow.org/). Even though TensorFlow may be a little easier to start with, PyTorch offers more flexibility, which is why we like to work with it.\n",
    "\n",
    "We will introduce you to `Tensors` and `Modules`, which are the base for all the helpful neural network building blocks in PyTorch. We will also show you how to prepare data for neural network training and how to build a simple network.\n",
    "\n",
    "We hope you will have fun and find this material useful.\n",
    "\n",
    "<img src=\"../figures/HeaDS_logo_large_withTitle.png\" width=\"200\">\n",
    "\n",
    "(This notebook was created by Viktoria Schuster)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "Tensors are THE data structure in machine learning. A tensor is a structure very similar to a numpy array, but it can be used on GPUs. And GPUs we really need if we don't want to get old waiting ...\n",
    "\n",
    "<img src=\"../figures/tensors_image.jpeg\" width=\"400\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics: initialization, shape, type and device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "You can create tensors from numpy arrays and various other data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the array:  [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# create a dummy array\n",
    "import numpy as np\n",
    "example_array = np.array([1, 2, 3, 4, 5])\n",
    "print(\"the array: \", example_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tensor:  tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# convert the array to a tensor\n",
    "import torch\n",
    "example_tensor = torch.tensor(example_array)\n",
    "print(\"the tensor: \", example_tensor)\n",
    "# there are more functions of how to convert to a tensor\n",
    "# but I like this general one because it is more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  6],\n",
       "        [ 2,  7],\n",
       "        [ 3,  8],\n",
       "        [ 4,  9],\n",
       "        [ 5, 10]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other initialization options\n",
    "# list\n",
    "torch.tensor([1,2,3,4,5])\n",
    "# tuple\n",
    "torch.tensor((1,2,3,4,5))\n",
    "# ranges\n",
    "torch.tensor(range(1,6))\n",
    "# floats and integers\n",
    "torch.tensor(0.5)\n",
    "# dataframes\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1,2,3,4,5], 'b': [6,7,8,9,10]})\n",
    "torch.tensor(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another very helpful one: create a tensor of zeros (great placeholder)\n",
    "\n",
    "# create a tensor of 2 zeros\n",
    "torch.zeros(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More creation options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#creation-ops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape, dtype and device\n",
    "\n",
    "A tensor has 3 attributes:\n",
    "- shape\n",
    "- data type\n",
    "- device\n",
    "\n",
    "these words you will often see in error messages, because PyTorch complains about shapes not matching, and data types and devices not being the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the array:  [1 2 3 4 5]\n",
      "with shape:  (5,)\n",
      "and dtype:  int64\n"
     ]
    }
   ],
   "source": [
    "example_array = np.array([1, 2, 3, 4, 5])\n",
    "print(\"the array: \", example_array)\n",
    "print(\"with shape: \", example_array.shape)\n",
    "print(\"and dtype: \", example_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tensor = torch.tensor(example_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape:  torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(\"tensor shape: \", example_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# tensors can have as many dimensions as you wish\n",
    "example_tensor2 = torch.zeros(2, 3)\n",
    "print(example_tensor2)\n",
    "print(\"shape: \", example_tensor2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor dtype:  torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(\"tensor dtype: \", example_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its size (in memory):  8\n",
      "new dtype:  torch.int8\n",
      "new size (in memory):  1\n"
     ]
    }
   ],
   "source": [
    "print(\"its size (in memory): \", example_tensor.element_size()) #returns size in bytes\n",
    "\n",
    "# you can initialize a tensor with a specific dtype\n",
    "example_tensor2 = torch.tensor(example_array, dtype=torch.int8)\n",
    "print(\"new dtype: \", example_tensor2.dtype)\n",
    "print(\"new size (in memory): \", example_tensor2.element_size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device\n",
    "\n",
    "The device is the location of the tensor on the computer. It will either be the CPU or GPU. The GPU makes things faster, so we love it. There are currently 3 options:\n",
    "- cpu\n",
    "- cuda (for NVIDIA GPUs)\n",
    "- mps (for some MAC GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor device:  cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"tensor device: \", example_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# you can check what you can use on your computer\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device available:  cpu\n",
      "device after moving:  cpu\n"
     ]
    }
   ],
   "source": [
    "# the device (where your tensor is stored) is CPU per default\n",
    "# if you have a GPU, you can move your tensor there\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device available: \", device)\n",
    "example_tensor = example_tensor.to(device)\n",
    "print(\"device after moving: \", example_tensor.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, slicing and concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row:  tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# select the first row\n",
    "result1 = tensor[0]\n",
    "\n",
    "print(\"first row: \", result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 2 columns:\n",
      " tensor([[1, 2],\n",
      "        [4, 5],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# select the first two columns\n",
    "result2 = tensor[:, :2]\n",
    "\n",
    "print(\"first 2 columns:\\n\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locations where tensor > 5:\n",
      " tensor([[False, False, False],\n",
      "        [False, False,  True],\n",
      "        [ True,  True,  True]])\n",
      "elements that are > 5 (or elements of the mask locations) tensor([6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# select elements with a Boolean mask\n",
    "mask = tensor > 5\n",
    "result3 = tensor[mask] # careful, this is not in the original structure anymore\n",
    "\n",
    "print(\"locations where tensor > 5:\\n\", mask)\n",
    "print(\"elements that are > 5 (or elements of the mask locations)\", result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# create two tensors\n",
    "tensor1 = torch.tensor([[1, 2],\n",
    "                        [3, 4]])\n",
    "tensor2 = torch.tensor([[5, 6],\n",
    "                        [7, 8]])\n",
    "\n",
    "# concatenate the two tensors along the second dimension\n",
    "result1 = torch.cat((tensor1, tensor2), dim=1)\n",
    "\n",
    "print(result1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two tensors\n",
    "tensor1 = torch.tensor([[1, 1],\n",
    "                        [2, 2]])\n",
    "tensor2 = torch.tensor([[1, 2],\n",
    "                        [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# add the two tensors element-wise\n",
    "result = torch.add(tensor1, tensor2)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These special element-wise operations give the same results as classic math operations (see below). However, using them instead of math operations can be more efficient. For small tensors, you don't have to worry about this though ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# add the two tensors element-wise\n",
    "result = tensor1 + tensor2\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#pointwise-ops)\n",
    "\n",
    "Some useful examples are\n",
    "- sub\n",
    "- mul\n",
    "- div\n",
    "- pow\n",
    "- exp\n",
    "- log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([[1, 2],\n",
    "                       [3, 4]])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sum the tensor along the first dimension\n",
    "result = torch.sum(tensor, dim=0)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#reduction-ops)\n",
    "\n",
    "Some useful examples are\n",
    "- mean\n",
    "- min\n",
    "- std\n",
    "- count_nonzero\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two matrices as tensors\n",
    "matrix1 = torch.tensor([[1, 1],\n",
    "                        [2, 2]])\n",
    "matrix2 = torch.tensor([[1, 2],\n",
    "                        [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  6],\n",
      "        [ 8, 12]])\n"
     ]
    }
   ],
   "source": [
    "# multiply the two matrices\n",
    "result = torch.matmul(matrix1, matrix2)\n",
    "# does [[m1(0,0)*m2(0,0) + m1(0,1)*m2(1,0)], [m1(1,0)*m2(0,0) + m1(1,1)*m2(1,0)]]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More options can be found [in the docs](https://pytorch.org/docs/stable/torch.html#blas-and-lapack-operations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced stuff\n",
    "\n",
    "Here are some -in my opinion- importent behaviours of tensors I wish I had known earlier, but they are not necessary to get started in Pytorch. Let's see how it goes in the course up until here. Otherwise, feel free to have a look yourselves."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Broadcasting is a PyTorch feature that enables you to perform element-wise operations on tensors with different shapes. In my opinion, this is one of the most useful but hidden features of torch.\n",
    "The rules about broadcasting are:\n",
    "- If two tensors have the same number of dimensions, their shapes must either be equal or one of them must be 1 in all dimensions.\n",
    "- If two tensors have different numbers of dimensions, the tensor with fewer dimensions is expanded by adding dimensions of size 1 on the left until the number of dimensions matches.\n",
    "\n",
    "Here is a figure demonstrating the rules:\n",
    "\n",
    "<img src=\"../figures/tensor_broadcasting.png\" width=\"300\">\n",
    "\n",
    "So let's have a look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4, 6],\n",
      "        [5, 7, 9]])\n"
     ]
    }
   ],
   "source": [
    "# tensor with shape (2, 3)\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "# tensor with shape (3,)\n",
    "tensor2 = torch.tensor([1, 2, 3])\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# tensor with shape (2,)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m tensor2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m result \u001b[39m=\u001b[39m tensor1 \u001b[39m+\u001b[39;49m tensor2\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# tensor with shape (2, 3)\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "# tensor with shape (2,)\n",
    "tensor2 = torch.tensor([1, 2])\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 4],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# tensor with shape (2, 3)\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "# tensor with shape (2, 1)\n",
    "tensor2 = torch.tensor([1, 2]).unsqueeze(1)\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor modification\n",
    "\n",
    "As briefly shown, we can change the dimensions and shapes of tensors as we please."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add and remove dimensions:\n",
    "- tensor.<span style=\"color:slateblue\">squeeze</span>() reduces a given dimension\n",
    "- tensor.<span style=\"color:slateblue\">unsqueeze</span>() adds a dimension in a given position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:\n",
      "    torch.Size([2, 3])\n",
      "unsqueezing the first dimension:\n",
      "    torch.Size([1, 2, 3])\n",
      "unsqueezing the second dimension:\n",
      "    torch.Size([2, 1, 3])\n",
      "unsqueezing the last dimension:\n",
      "    torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "\n",
    "print(\"original shape:\\n   \", tensor1.shape)\n",
    "print(\"unsqueezing the first dimension:\\n   \", tensor1.unsqueeze(0).shape)\n",
    "print(\"unsqueezing the second dimension:\\n   \", tensor1.unsqueeze(1).shape)\n",
    "print(\"unsqueezing the last dimension:\\n   \", tensor1.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of squeezed tensor:\n",
      "    torch.Size([2, 3])\n",
      "new tensor of shape:\n",
      "    torch.Size([1, 3])\n",
      "shape of the squeezed new tensor:\n",
      "    torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# what can we squeeze?\n",
    "\n",
    "# if the dimension to be squeezed is larger than 1, nothing happens\n",
    "print(\"shape of squeezed tensor:\\n   \", tensor1.squeeze(0).shape)\n",
    "\n",
    "tensor2 = torch.tensor([[1, 2, 3]])\n",
    "print(\"new tensor of shape:\\n   \", tensor2.shape)\n",
    "print(\"shape of the squeezed new tensor:\\n   \", tensor2.squeeze(0).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the shapes completely\n",
    "- tensor.<span style=\"color:slateblue\">view</span>()\n",
    "- tensor.<span style=\"color:slateblue\">expand</span>()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can understand viewing and reshaping as taking the tensor's values in their natural occurance, that means our tensor\n",
    "\n",
    "| | c1 | c2 | c3 |\n",
    "| --- | :---: | :---: | :---: |\n",
    "| r1 | 1 | 2 | 3 |\n",
    "| r2 | 4 | 5 | 6 |\n",
    "\n",
    "Is first going by row, then by column. The order of elements can be seen by flattening the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "print(tensor1.flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using view, the tensor elements are sorted into the new defined shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.view(3,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also let torch do some of the thinking for me. If I have a 2d tensor, I only have to specify the new size of one dimension, the other one will be defined `automatically`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.view(-1,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are these reshaped tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory address of tensor1:\n",
      " 0x7f7b8b56cf40\n",
      "memory address of tensor2:\n",
      " 0x7f7b8b56cf40\n"
     ]
    }
   ],
   "source": [
    "print(\"memory address of tensor1:\\n\",hex(tensor1.storage().data_ptr()))\n",
    "\n",
    "tensor2 = tensor1.view(-1)\n",
    "\n",
    "print(\"memory address of tensor2:\\n\",hex(tensor2.storage().data_ptr()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that tensor1 and tensor2 have the same memory address?\n",
    "The view is not creating a new tensor, but just a different `view` on the same tensor. We call tensor2 a `pointer`. If you want this as a new and independent tensor, make a copy of unsing tensor.<span style=\"color:slateblue\">clone</span>()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory address of tensor2:\n",
      " 0x7f7b8b572a40\n"
     ]
    }
   ],
   "source": [
    "tensor2 = tensor1.clone().view(-1,2)\n",
    "print(\"memory address of tensor2:\\n\",hex(tensor2.storage().data_ptr()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't just need a new view, but for some reason you need to make the tensor bigger in some dimension, you can use tensor.<span style=\"color:slateblue\">expand</span>()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor size:\n",
      " torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = torch.tensor([[1, 2, 3]])\n",
    "print(\"original tensor size:\\n\", tensor3.shape)\n",
    "\n",
    "# expanding the tensor in dimension 0 (first dimension), keeping the other dimension the same\n",
    "tensor3.expand(2, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and Modules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "\n",
    "Machine learning involves the optimization of trainable parameters. The `Parameter` is a tensor subclass. Its special property is that it can receive gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# initializing an empty parameter tensor\n",
    "param = torch.nn.Parameter()\n",
    "print(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module\n",
    "\n",
    "The `Module` class is a container and the base class for neural networks in PyTorch. You can create any model you want based on this with keeping in mind 3 things:\n",
    "- it needs an `__init__()` constructor\n",
    "- remember to initialize the parent class in the initialization (basic class stuff)\n",
    "- it needs a `forward()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3468, -0.7039],\n",
      "        [ 1.0307, -0.7146]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# let's create a dummy child of Module\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = torch.nn.Parameter(torch.randn(2, 2))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.weights * x + self.bias\n",
    "\n",
    "linear = SimpleLinear()\n",
    "\n",
    "input_vals = torch.randn(2)\n",
    "\n",
    "output_vals = linear(input_vals)\n",
    "\n",
    "print(output_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders\n",
    "\n",
    "PyTorch helps us a lot with the data during training. `Dataloaders` create random splits of the data in every epoch of training for us, but they do need to know how to get the data and what the data is exactly. This is where the `Dataset` class comes in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Let's find a super simple dataset to work with. Many of you may be familiar with the iris dataset from R. We also have this in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "# import some super basic data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "print(iris.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `Dataset` class, we can prepare the iris dataset for PyTorch. We will need to inherit the PyTorch `Dataset` class and specify our `__init__()`, `__len__()` and `__getitem__()` constructors.\n",
    "\n",
    "The dataloader only accepts certain types of data. Among these are tensors and numpy arrays. So we should also know what format our data is in and change it if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris data is so far in dataframe format, so we will transform them into tensors in our `__init__()` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Dataset class for the iris data\n",
    "\n",
    "# import torch and the Dataset class\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IrisDataset(Dataset):\n",
    "    \"\"\"This is a child of Dataset providing the iris data to the dataloader\n",
    "    The init and getitem constructors are absolutely necessary\"\"\"\n",
    "    def __init__(self, data, targets):\n",
    "        super().__init__()\n",
    "        self.data = torch.Tensor(data.values)\n",
    "        self.targets = torch.Tensor(targets.values)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # for a given index, return the data and target\n",
    "        return self.data[idx,:], self.targets[idx]\n",
    "\n",
    "iris_dataset = IrisDataset(iris.data, iris.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was already the most complicated part in dealing with data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "Now we are ready to use a dataloader to provide us with random batches of our data during training. There is a lot in the docs that makes it look complicated, but don't worry. Getting started with dataloaders is really simple. For a while, you will not need more than this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000]])\n",
      "tensor([2., 2., 0., 0., 2., 0., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "# now we can create a dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "iris_dataloader = DataLoader(iris_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# now we can iterate over the dataloader\n",
    "for data, target in iris_dataloader:\n",
    "    print(data)\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks in PyTorch\n",
    "\n",
    "Let's put our knowledge to use and see how one builds a neural network in PyTorch for a given task. If we stick to the iris dataset from before, we know that we have 4 features for every datapoint (flower) and want to predict the species.\n",
    "\n",
    "This already gives us a lot of information about what we should do. We want to build a classifier that takes the 4 features as input and spits out the probabilities of each species."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start with a class inheriting the `nn.Module` again as we have done before. Now we will use some more modules and functions that PyTorch provides in order to do actual machine learning. There are lots of nice building blocks that we can use, [have a look](https://pytorch.org/docs/stable/nn.html).\n",
    "\n",
    "We often call these building blocks `Layers`. They are also PyTorch `Modules` with specific parameters and operations that are executed for you. We will start very simple, with linear layers and rectified linear activation. The `Linear` layer applies a simple linear transformation to data $x$:\n",
    "\n",
    "$ y = xA^T + b$. with weight matrix $A$ and bias $b$ being trainable parameters of class `Parameter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a little classifier for iris\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the network\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features:int, hidden_features:int, out_features:int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear( # define the first fully connected layer\n",
    "            in_features,\n",
    "            hidden_features\n",
    "        )\n",
    "        self.fc2 = nn.Linear( # define the second fully connected layer\n",
    "            hidden_features,\n",
    "            out_features\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.fc1(x) # apply the first fully connected layer\n",
    "        z = F.relu(z) # apply the relu activation function (non-linearity)\n",
    "        z = self.fc2(z) # apply the second fully connected layer\n",
    "        return F.softmax(z, dim=1) # apply the softmax activation function to return probabilities for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_classifier = Classifier(in_features=4, hidden_features=64, out_features=3) # create an instance of the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an example, we can get a better intuition about how the Linear layer works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an input sample would have the shape:  torch.Size([1, 4])\n",
      "the first layer weights have the shape:  torch.Size([64, 4])\n",
      "the first layer bias has the shape:  torch.Size([64])\n",
      "the first layer output is of shape:  torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "### printing some things that happen in the network forward pass and architecture\n",
    "dummy_input = torch.randn(1, 4)\n",
    "print(\"an input sample would have the shape: \", dummy_input.shape)\n",
    "print(\"the first layer weights have the shape: \", iris_classifier.fc1.weight.shape)\n",
    "print(\"the first layer bias has the shape: \", iris_classifier.fc1.bias.shape)\n",
    "print(\"the first layer output is of shape: \", iris_classifier.fc1(dummy_input).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear layer does in principle this (but more efficient in C):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "pseudo_linear_output = torch.matmul(dummy_input, iris_classifier.fc1.weight.t()) + iris_classifier.fc1.bias\n",
    "print(pseudo_linear_output.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ReLU activation is one of the simplest and most popular activation functions and looks like this:\n",
    "\n",
    "<img src=\"../figures/ReLU_pytorch.png\" width=\"300\">\n",
    "\n",
    "(image from [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

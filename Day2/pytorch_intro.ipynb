{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../figures/HeaDS_logo_large_withTitle.png\" width=\"300\">\n",
    "\n",
    "# Introduction to pytorch\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Center-for-Health-Data-Science/IntroToML/blob/HEAD/Day2/pytorch_intro.ipynb)\n",
    "\n",
    "- presents key components of pytorch and python concepts\n",
    "- retrain linear regression of previous exercise using pytorch\n",
    "- add Feed Forward Neural Network\n",
    "\n",
    "Put together by [Henry Webel](https://twitter.com/Henrywebel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Disclamer: The notebook is in support of a presentation, not the replacement (so I do not write out everything)\n",
    "\n",
    "## Outline\n",
    "- Torch seen as numpy: `Ndarray` -> `Tensor`\n",
    "\t- Why: Tensor itself has backprop information\n",
    "- Key Concepts and associated Classes: \n",
    "    - brief recap of python concepts needed: `tuple`, `[ ]` implementation, `len`, `Callable`\n",
    "    - `DataSet` -> `__getitem__`, `__len__`\n",
    "    - `DataLoader` -> Loop over `Dataset` in certain ways\n",
    "    - Model formulation -> `Module` as a `Callable`\n",
    "    - Optimizers -> `SGD`\n",
    "    - loss functions\n",
    "\n",
    "- plan:\n",
    "    * Start by makig a Dataset and one DataLoader. \n",
    "    * hint on `DataLoader`s for validaiton + training. \n",
    "    * Define a simple linear regression\n",
    "    * Do one step with `Dataloder` + model and see what comes out\n",
    "    * Do it in a loop\n",
    "    * Define a feed-forward network as an exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Further material\n",
    "The Colab I found before: Primer on NNs, (or this one?), cheat-cheets (and as a notebook)\n",
    "\n",
    "- Textbook: [Deep Learning with PyTorch](https://github.com/deep-learning-with-pytorch/dlwpt-code)\n",
    "- [pytorch.org Cheat Sheet](https://pytorch.org/tutorials/beginner/ptcheat.html), or examples from some blog (lost source) in [tensor_cheatsheet.ipynb](tensor_cheatsheet.ipynb)\n",
    "- notebook on [classes](https://github.com/Center-for-Health-Data-Science/PythonTsunami/tree/fall2021/Classes)\n",
    "\n",
    "- a [primer tutorial](https://github.com/sweetpand/PyTorch_fun/blob/master/pytorch_primer.ipynb) for PyTorch\n",
    "- simple [toy example](https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/p1ch6/1_neural_networks.ipynb) for a Linear Regression from Deep Learning with Pytorch book\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ2ayTn6J9oO",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arrays\n",
    "\n",
    "- Indexed sets of related elements.\n",
    "- Often data of the same type continously layed out in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Numpy\n",
    "    \n",
    "<img src=\"https://numpy.org/images/logos/numpy_logo.svg\" width=\"200\">\n",
    "    \n",
    "See notebook by [Jakob Nybo Nissen](https://twitter.com/nybojakob), continued by [Henry Webel](https://twitter.com/Henrywebel): [Arrays_numpy.ipynb](Arrays_numpy.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Center-for-Health-Data-Science/PythonTsunami/blob/fall2021/Numpy/Arrays_numpy.ipynb)\n",
    "    \n",
    "- The first half of this Notebook contain a small introduction to `numpy`. You can also watch a [the YouTube video](https://www.youtube.com/watch?v=8Mpc9ukltVA). If you feel comfortable using [`numpy`](https://numpy.org/), you can skip the introduction and go directly to the [exercises (click here)](#exercises). If you would like a recap, keep reading on.\n",
    "    \n",
    "- Other informative overviews of `numpy` with lots of examples can be found [here](https://jalammar.github.io/visual-numpy/) and [here](https://betterprogramming.pub/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ2ayTn6J9oO",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[`numpy`](https://numpy.org/) is a Python package that provides a new type of object: The `ndarray`. This is an N-dimensional array, i.e. a \"list\" with any number of dimensions.\n",
    "`numpy` is one of the most fundamental Python packages. Almost all of scientific Python uses [`numpy`](https://numpy.org/) either directly, or indirectly through another package.\n",
    "\n",
    "[![Figure 2, Harris et. al. 2020](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41586-020-2649-2/MediaObjects/41586_2020_2649_Fig2_HTML.png?as=webp)](https://www.nature.com/articles/s41586-020-2649-2/figures/2)\n",
    "\n",
    "It may not be immediately clear why [`numpy`](https://numpy.org/)'s `ndarrays` are so useful that they are everywhere. Do ALL scientific software really need N-dimensional arrays? As you will learn in these exercises, even for 1-dimensional data that *could* be placed in lists, `ndarrays` are generally useful for their convenience and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ2ayTn6J9oO",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reference\n",
    "Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., del Río, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. Nature, 585(7825), 357–362. https://doi.org/10.1038/s41586-020-2649-2\n",
    "\n",
    "\n",
    "[![Figure1, Harris et. al. 2020](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41586-020-2649-2/MediaObjects/41586_2020_2649_Fig1_HTML.png?as=webp)](https://www.nature.com/articles/s41586-020-2649-2/figures/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l_values = [4, 9, 1, 0, 8, 3, 2, 2, 6, 5, 0, 8]\n",
    "ndarray = np.ndarray(l_values)\n",
    "type(ndarray), ndarray  # what does this construct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pytorch\n",
    "\n",
    "- implements Arrays with the option to keep track of information needed for backpropagation\n",
    "- numpy and pytorch Arrays can share memory\n",
    "\n",
    "\n",
    "More on history and tensor implementation: See [Deep Learning with PyTorch](https://github.com/deep-learning-with-pytorch/dlwpt-code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch  # note: does not say pytorch\n",
    "tensor = torch.tensor(l_values)\n",
    "type(tensor), tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tensor.shape, tensor.reshape((-1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Dataset`\n",
    "\n",
    "\n",
    "A collection of data. see [docs](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset)\n",
    "\n",
    "- normally should have integer keys (\"integral keys\")\n",
    "- needs `__getitem__` and `__len__` to work in ensample with other core classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Python recap\n",
    "\n",
    "Among others a collection of things (e.g. a `Dataset`) is emulated/imitated using:\n",
    "- if an object can be accessed using square brackets `obj[...]` then it has a `__getitem__` method\n",
    "- if an objects length can be queried, it needs an `__len__` method\n",
    "\n",
    "check out [Fluent Python](https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/) by Luciano Ramelho to learn this.\n",
    "Let's consider [one of the first examples](https://github.com/fluentpython/example-code-2e/blob/master/01-data-model/frenchdeck.py) from the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "\n",
    "\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA')\n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "\n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits\n",
    "                       for rank in self.ranks]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "\n",
    "    def __getitem__(self, position):\n",
    "        return self._cards[position]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is enough to implement a slicable collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "french_deck = FrenchDeck()\n",
    "french_deck[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "french_deck[-1], len(french_deck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATASET_URL = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n",
    "DATASET_FNAME = \"covid_data_denmark.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_FNAME, parse_dates=['date'], index_col=\"date\")\n",
    "    print(\"loaded data from disk\")\n",
    "except FileNotFoundError:\n",
    "    print(\"load data from internet\")\n",
    "    df = pd.read_csv(DATASET_URL, parse_dates=['date'], index_col=\"date\")\n",
    "    df = df.query(\"location in ['Denmark']\")\n",
    "    df = df.loc[\"2020-03-14\": \"2020-07-31\"]\n",
    "    mask = df[[\"new_cases\", \"new_deaths\"]].notna().all(axis=1)\n",
    "    df = df.loc[mask]\n",
    "    df.to_csv(DATASET_FNAME)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind='scatter', x=\"new_cases\", y=\"new_deaths\", figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pytorch `Dataset` for covid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CovidDenmarkData(Dataset):\n",
    "    \"\"\"Preliminary class.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame,\n",
    "                 x=['new_cases'], y=['new_deaths']):\n",
    "        self._df = df[x+y]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self._df.iloc[idx]\n",
    "        x = row[self.x]\n",
    "        y = row[self.y]\n",
    "        return torch.as_tensor(x), torch.as_tensor(y).squeeze()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "\n",
    "dataset = CovidDenmarkData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataset[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "- Easy: Add more features to x\n",
    "- Advanced (?): Try to implement the Dataset with numpy.ndarray to share data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MyCovidDenmarkData(Dataset):\n",
    "    \"\"\"which definitely shares data.\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `DataLoader`\n",
    "\n",
    "- from the [docs](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader):\n",
    "\n",
    "> Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "\n",
    "- assembles data to mini-batches, during training buy collecting random items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "DataLoader?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset=dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dl.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A DataLoader is an `Iterable`\n",
    "\n",
    "> \"Iterable: An object capable of returning its members one at a time. Examples of iterables include all sequence types (such as list, str, and tuple) and some non-sequence types like dict, file objects, and objects of any classes you define with an `__iter__()` method or with a `__getitem__()` method that implements Sequence semantics.\" ([glossary](https://docs.python.org/3/glossary.html))\n",
    "\n",
    "- can be used in for loops\n",
    "- can provide a generator using the built-in `iter` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for x in dl:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Optional Exercise (for later)\n",
    "\n",
    "- Is a `Dataset` also an `Iterable` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DataLoaders: More than one `Dataloader`\n",
    "\n",
    "- data is often split into training, validation and testing data\n",
    "- training and validation data is used during training (-> see next lectures on overfitting)\n",
    "\n",
    "Sometimes you find collections of `DataLoader` into custom `DataLoaders` classes, basically a tuple.\n",
    "So it can be either purely both semantic and conceptually, or additionally represented in custom code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N_train = int(len(df)*0.8)\n",
    "print(f\"N_total: {len(df)}, N_train: {N_train}, N_val: {len(df)- N_train}\")\n",
    "df_randomized = df.sample(frac=1.0)\n",
    "dataset_train = CovidDenmarkData(df_randomized.iloc[:N_train])\n",
    "dataset_valid = CovidDenmarkData(df_randomized.iloc[N_train:])\n",
    "\n",
    "print(f\"Train: {len(dataset_train)}, Valid: {len(dataset_valid)}\")\n",
    "\n",
    "data_loaders = (\n",
    "    DataLoader(dataset_train, shuffle=True),\n",
    "    DataLoader(dataset_valid, shuffle=False)\n",
    ")\n",
    "\n",
    "len(data_loaders[1])  # A tuple as a collection of single DataLoader instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Models\n",
    "\n",
    "- are `Callable`s\n",
    "- A model is a collection, often sequence, of `Module`s\n",
    "- [`Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) is the most common model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Excurs: `Callable` in Python\n",
    "\n",
    "- means that it support to be called using normal parantheses `obj()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def do_something():\n",
    "    return 3\n",
    "\n",
    "\n",
    "class DoSomething():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"Make an instance Callable.\"\"\"\n",
    "        return 6\n",
    "\n",
    "\n",
    "do_something_instance = DoSomething()  # here init is called\n",
    "\n",
    "do_something(), do_something_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear Module\n",
    "\n",
    "- the linear module alone can be used to formulate a linear model:\n",
    "\n",
    "    $f(x) = \\sum_{i} x_i * w_i + b$, where  \n",
    "      \n",
    "    there is a weight $w_i$ for each input feature $x_i$ and an overall bias (or intercept) $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "linear_model = nn.Linear(1, 1)  # <1>\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# linear_model(x[0]) # RuntimeError: expected scalar type Float but found Double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You well see several in-place operations throughout pytorch code\n",
    "  - transforming data\n",
    "  - specifying data location in memory (which one to use)\n",
    "\n",
    "In general data and model have to be of the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "linear_model.double()  # data is float64, so model parameters also need to be float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Provide a mini-batch to the untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# a random first batch from our DataLoader (iff shuffle is True)\n",
    "x = next(iter(dl))\n",
    "linear_model(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nn.Linear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train Linear Regression parameters\n",
    "\n",
    "- again using Stochastic Gradient Descent, , using [`torch.optim.SDG`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html?highlight=sgd#torch.optim.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "sgd = SGD(params=linear_model.parameters(), lr=1.e-5)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### One mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_in, y_true = next(iter(dl))\n",
    "y_predicted = linear_model(x_in).squeeze()\n",
    "y_predicted, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(y_predicted, y_true)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sgd.zero_grad()\n",
    "loss.backward()\n",
    "sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = linear_model(x_in).squeeze()\n",
    "y_predicted, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Train in epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "lr = 1.e-5\n",
    "\n",
    "\n",
    "linear_model = nn.Linear(1, 1).double()  # repeat\n",
    "\n",
    "print(\n",
    "    f\"initial weight: {linear_model.weight.squeeze()}, initial bias: {linear_model.bias.squeeze()} \")\n",
    "\n",
    "sgd = SGD(params=linear_model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "num_epochs = 20  # Number of epochs to run\n",
    "loss_history = []  # Keep a record of losses over time for plotting\n",
    "\n",
    "plot = sns.regplot(data=df, x=\"new_cases\", y=\"new_deaths\",\n",
    "                   ci=None).set(xlabel='New cases', ylabel='Deaths')\n",
    "\n",
    "# df.plot(kind='scatter', x=\"new_cases\", y=\"new_deaths\", figsize=(15,10))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0  # reset epoch loss\n",
    "    for x_in, y_true in dl:\n",
    "        # Zero out gradients (clean-up of optimizer)\n",
    "        sgd.zero_grad()\n",
    "        # Forward pass\n",
    "        y_predicted = linear_model(x_in)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(\n",
    "            y_predicted.squeeze(),  # remove squeeze and see what happens -> shapes are important\n",
    "            y_true)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Clean up\n",
    "        sgd.step()\n",
    "        # add mini-batch loss\n",
    "        epoch_loss = epoch_loss + loss.item()  # item returns a numpy array\n",
    "\n",
    "    # plot parameters after epoch\n",
    "    w, b = linear_model.weight.detach().numpy(), linear_model.bias.detach().numpy()\n",
    "    x = df['new_cases'].to_numpy()\n",
    "    plt.plot(x, (x*w+b).squeeze(), color=\"blue\", linewidth=0.2)\n",
    "\n",
    "    print(f'epoch: {epoch:4d}, epoch loss: {epoch_loss}')\n",
    "    loss_history.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_in, y_true = next(iter(dl))\n",
    "y_predicted = linear_model(x_in).squeeze()\n",
    "y_predicted, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "linear_model.weight, linear_model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custom `Module`s, Custom models\n",
    "\n",
    "- the Callable is implemented as a forward method for programmming pattern reasons (let's exclude discussion of automated programming interfaces - APIs - for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Everything stateful which you need to use your model goes here.\"\"\"\n",
    "        super().__init__()  # needs to be here for API reasons -> call nn.Module.__init__\n",
    "        pass\n",
    "\n",
    "    def forward(self):  # no input\n",
    "        return \"define your model here\"\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# nn.Module.__call__?? # have a look if you are interested in API separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us define the model as it was done in the previous step, wrapped into a `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Everything stateful which you need to use your model goes here.\"\"\"\n",
    "        super().__init__()  # needs to be here for API reasons -> call nn.Module.__init__\n",
    "        self.linear_reg = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):  # now with input\n",
    "        return self.linear_reg(x)\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "x = torch.tensor([20, 30, 40], dtype=torch.float32).unsqueeze(-1)\n",
    "lin_reg(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "- Use this model with the training loop above\n",
    "- (Advanced) If you have time and are interested: can you initialise the weight and bias to 0 (this will require re-initializing the weights, [check](https://pytorch.org/docs/stable/nn.init.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# copy training loop and try to get it running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "- create a Feed-Forward Neural Network (FNN)\n",
    "- Adapt the [FNN from the tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#define-the-class). You will see the use of  `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# copy traiing loop and try to get your way to complex model running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Additional Exercises\n",
    "\n",
    "- prepare data in `float32` in `Dataset`(or `DataFrame`)\n",
    "- cast model differently (after adapting the data)\n",
    "- add the batchsize for configurations in the training loop (-> `DataLoader`)\n",
    "- report the loss as per sample loss, not as aggregated batch loss\n",
    "- can try to add more features than one to the model for making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outlook\n",
    "\n",
    "The training procedure can be simplified using libraries built on top of pytorch.\n",
    "\n",
    "- [Lightning](https://www.pytorchlightning.ai/)\n",
    "- [Ignite](https://pytorch.org/ignite/quickstart.html)\n",
    "- [fastai](https://docs.fast.ai/)\n",
    " \n",
    "\n",
    " > Warning: The simplification or standardization of training procedures is another layer of \n",
    " > complexity itself"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_intro.ipynb",
   "provenance": [
    {
     "file_id": "1RWt6QETnGQ9VKrSOsop56XanZavkoQM9",
     "timestamp": 1606991634276
    }
   ],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "cf83e9cb890c7f96eb0ae04f39a82254555f56a1a0ed2f03b23a8b40fe6cd31c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "rise": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "333.991px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

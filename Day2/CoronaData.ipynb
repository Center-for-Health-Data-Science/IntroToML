{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Center-for-Health-Data-Science/IntroToML/blob/main/Day2/CoronaData.ipynb","timestamp":1681706069021}],"collapsed_sections":["CsQoZxtU5CoQ","sgilTt-942ZV","IYs20lPJ5vvV"],"authorship_tag":"ABX9TyMGwQptj0e0Ge6Qz+ZL8L62"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Linear regression by gradient descent\n","\n","To illustrate gradient descent, we make simple linear regression. In linear regression, we want to determine the parameters $a$ and $b$ for the line $$ y= ax+b $$ from a set of $n$ points $x_i,y_i$.\n","\n","We find the parameters that minimize the mean squared error (the difference between the line and the actual points)\n","$$\n","E(a,b) = \\frac{1}{n}\\sum_i (ax_i+b-y_i)^2\n","$$\n","\n","This is normally done using an analytical expression for $a$ and $b$, but here we want to illustrate how it can be done minimizing by gradient descent.\n","\n"],"metadata":{"id":"TgZqc_X_eRhY"}},{"cell_type":"markdown","source":["## Data on COVID-19 infections and deaths in Denmark"],"metadata":{"id":"CsQoZxtU5CoQ"}},{"cell_type":"markdown","source":["\n","We use some data for the number of COVID-19 infections and deaths per day in Denmark. The goal is to see if there is a linear relation between these in the first wave in 2020.\n","\n","Below, the data are downloaded and read into a pandas dataframe. Then we do normal linear regression."],"metadata":{"id":"XDppxJDijx7b"}},{"cell_type":"code","source":["# These are the libraries used in this  notebook\n","import numpy as np\n","import pandas as pd\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"],"metadata":{"id":"EC-sUhGDn7zt","executionInfo":{"status":"ok","timestamp":1713675389394,"user_tz":-120,"elapsed":2119,"user":{"displayName":"Anders Krogh","userId":"14176282564609376342"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNsTTAYJnOPV"},"outputs":[],"source":["%%bash\n","# Here I use bash (Linux commands). It is not important to understand.\n","# Download data from https://ourworldindata.org/\n","rm -f owid-covid-data.csv*\n","wget -q 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n","# Extract header and data from Denmark only\n","head -1 owid-covid-data.csv > Covid_Denmark.csv\n","grep -i denmark owid-covid-data.csv >> Covid_Denmark.csv\n","echo 'The files in your colab directory and their sizes:'\n","ls -lh"]},{"cell_type":"markdown","source":["We use the file Covid_Denmark.csv. We first read it into a pandas dataframe (df)"],"metadata":{"id":"NsfFhZC3BZ64"}},{"cell_type":"code","source":["# Read file into pandas dataframe and print column names\n","df = pd.read_csv('Covid_Denmark.csv',parse_dates=['date'])"],"metadata":{"id":"fBTYt983pEyj","executionInfo":{"status":"ok","timestamp":1713675878487,"user_tz":-120,"elapsed":310,"user":{"displayName":"Anders Krogh","userId":"14176282564609376342"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Take a look at the data. The head method shows the first n lines\n","# NaN means \"Not a Number\". These are missing values\n","df.head(n=10)"],"metadata":{"id":"HhRe5lNDB1US"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# You can see column names if you want\n","print(df.columns)"],"metadata":{"id":"P_8jGku7BwSh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Include only initial corona wave from Mar 2020 to July 2020\n","# Exclude NAN values\n","t1 = pd.to_datetime(\"03-01-2020\")\n","t2 = pd.to_datetime(\"08-01-2020\")\n","# Select rows which are not NAN in \"new_cases\" and \"new_deaths\"\n","# and in the right date interval\n","dfe = df[ (df['date']>t1) & (df['date']<t2) &\n","         df['new_cases'].notna() & df['new_deaths'].notna() ]\n"],"metadata":{"id":"8pGSO8s0rsF0","executionInfo":{"status":"ok","timestamp":1713676070577,"user_tz":-120,"elapsed":304,"user":{"displayName":"Anders Krogh","userId":"14176282564609376342"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Extract relevant columns from the data frame into Numpy arrays\n","\n","x = (dfe['new_cases']*1.0).to_numpy()\n","y = (dfe['new_deaths']*1.0).to_numpy()\n","\n","# Seaborn can do linear regression with regplot\n","sns.regplot(x=x,y=y,ci=None).set(xlabel='New cases',ylabel='Deaths')\n","\n","plt.show()"],"metadata":{"id":"3ITHSpahqg1l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The gradient and helper functions"],"metadata":{"id":"sgilTt-942ZV"}},{"cell_type":"markdown","source":["Here we define the linear function that we would like to fit, we define the 'loss' function, which is the mean squared error.\n","\n","We also make a function to calculate the gradient. By differentiation, the gradient of the error can be calculated (it is not important to understand the math):\n","$$\n","\\left(\\frac{\\partial E}{\\partial a},\\frac{\\partial E}{\\partial b}\\right)\n","= \\left( \\frac{2}{n} \\sum_i(ax_i+b-y_i)x_i,\n","\\frac{2}{n}\\sum_i(ax_i+b-y_i) \\right)\n","$$\n"],"metadata":{"id":"8c3NYfZz4emn"}},{"cell_type":"code","source":["# These functions take numpy arrays (x and y) and paramters a,b\n","\n","def linear_function(x,a,b):\n","  return a*x+b\n","\n","def mean_squared_error(y,x,a,b):\n","  ''' Mean squared difference (error) between points and line '''\n","  n = x.shape[0]\n","  return np.square(y-linear_function(x,a,b)).sum()/n\n","\n","def gradient(y,x,a,b):\n","  n = x.shape[0]\n","  c = 2*(a*x+b-y)/n\n","  return (c*x).sum(),c.sum()\n"],"metadata":{"id":"6ttKJJ8oiIc5","executionInfo":{"status":"ok","timestamp":1713676303766,"user_tz":-120,"elapsed":372,"user":{"displayName":"Anders Krogh","userId":"14176282564609376342"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Gradient descent"],"metadata":{"id":"IYs20lPJ5vvV"}},{"cell_type":"markdown","source":["To illustrate the used of gradient descent minimization, we use it here to find the two parameters for linear regression."],"metadata":{"id":"GG98h0oQ55Sx"}},{"cell_type":"code","source":["# An epoch is one step/round of gradient descent\n","# This is the number of rounds we do:\n","nepochs=20\n","\n","# Start values for the two paramters\n","a=0.0\n","b=0.0\n","\n","# The step size for gradient descent (1.e-6 gives a nice illustration)\n","learn_rate = 1.e-6\n","\n","# Same plot as above with the correct regression line\n","plot = sns.regplot(x=x,y=y,ci=None).set(xlabel='New cases',ylabel='Deaths')\n","plt.legend(labels=['Data points','Standard linear regression'])\n","\n","# For changing line colors (found somewhere on the internet...)\n","import itertools\n","palette=itertools.cycle(sns.light_palette(sns.color_palette()[0],nepochs))\n","\n","for epoch in range(nepochs):\n","  # Plot the line resulting from the current values of a and b\n","  plt.plot(x,linear_function(x,a,b),color=next(palette), linewidth=0.2)\n","  # This is very slow: sns.lineplot(x=x,y=linear_function(x,a,b),color=next(palette))\n","\n","  # The error\n","  err = mean_squared_error(y,x,a,b)\n","  # Calculate gradient\n","  da,db=gradient(y,x,a,b)\n","  # Change parameters by gradient descent\n","  a -= learn_rate*da\n","  b -= learn_rate*db\n","  # b converges VERY slowly. You can use b -= 10000*learn_rate*db to speed up\n","  if (epoch+1) % (nepochs//5)==0:\n","    print(\"Epoch:\",epoch+1,\"Error:\",err, \"a,b: \",a,b)\n","\n","err = mean_squared_error(y,x,a,b)\n","print(\"Final epoch\",epoch+1,\"Error :\",err)\n","\n","# Plot last line in color red\n","sns.lineplot(x=x,y=linear_function(x,a,b),color=\"red\")\n","\n","plt.show()\n"],"metadata":{"id":"UfPBfmzwsAb2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can try to change the learning rate. If it is too big, it will go completely wrong, and if it is too small, it will not converge."],"metadata":{"id":"Y7HOcFel7IMy"}}]}
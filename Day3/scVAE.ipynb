{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b2d1a0-3743-4b05-babe-854596362593",
   "metadata": {},
   "source": [
    "# Generative Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3840c5-ca83-41e2-8639-d46605166e13",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Center-for-Health-Data-Science/IntroToML/blob/HEAD/Day3/scVAE.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024cb46-c21f-47ca-bac3-9ee60220ffb7",
   "metadata": {},
   "source": [
    "In this exercise, we will use a variational autoencoder (VAE) to model single-cell RNA-sequencing (scRNA-seq) gene expression data. scVAE ([Grønbech *et al.*, 2020](https://academic.oup.com/bioinformatics/article/36/16/4415/5838187)) is designed for this.\n",
    "\n",
    "A VAE can encode a data set into a latent representation using a inference model (encoder) and decode the latent representation to reconstruct the data set using a generative model (decoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078e19d-2ac9-49ba-863d-81b0f8345c19",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2bffb-ce70-4f39-a694-5a10ca45ff28",
   "metadata": {},
   "source": [
    "We will use a development version of scVAE, so ignore any warnings that occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da420309-6a82-4cdb-b1d8-a7d66d01158a",
   "metadata": {},
   "source": [
    "Install scVAE and ScanPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c577012-b468-47d6-a3cf-6a88db8595ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -q https://people.compute.dtu.dk/chegr/scvae/scvae-3.0.0.dev0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7851147-d81c-4595-a149-1a79ed88c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -q scanpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1314bf9-a141-47b0-8a94-414b35f6b083",
   "metadata": {},
   "source": [
    "Restart the kernel (Kernel > Restart Kernel...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f633b9-625f-498d-b6b1-539ce65a041d",
   "metadata": {},
   "source": [
    "Import scVAE and other packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bede84-dcf1-4ea9-ac9b-972bd56f0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvae\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2a96d-445f-40bd-9772-a88e8191ab74",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59305e-459c-4e24-995a-8da0d51d78a7",
   "metadata": {},
   "source": [
    "We will work with a data set of single-cell RNA-sequencing (scRNA-seq) gene expression data from lupus and healthy patients ([Perez *et al.*, 2022](https://www.science.org/doi/10.1126/science.abf1970)). Since this is a very large data set of 1.2 million cells and 31000 genes, it has been preprocessed resulting in a much smaller size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380cbeb-64dc-4b52-b8df-6f5d68de3dbb",
   "metadata": {},
   "source": [
    "Download preprocessed lupus scRNA-seq data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48226fb0-26d9-4972-8906-d17c0895774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://people.compute.dtu.dk/chegr/scvae/lupus.h5ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0660d59d-44bb-4fd5-b994-6d19747b3bb9",
   "metadata": {},
   "source": [
    "Load data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baaf3b0-c330-474e-95e1-9f0bf1fb6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus = sc.read(\"lupus.h5ad\")\n",
    "lupus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c4e3f-3c62-404a-a9e7-248d80622286",
   "metadata": {},
   "source": [
    "This is an annotated data set, and `obs` refer to the observations, which are the cells, and `var` refer to the variables, which are the genes. The preprocessed gene expression levels for each cell and each gene are stored in the `X` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e4003-04fb-4b87-b14e-7b54d72eb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus.X.A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee3ead-7807-4890-8248-4540e9512075",
   "metadata": {},
   "source": [
    "However, we will use the raw gene expression counts stored in the \"counts\" layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be81192-6259-426a-ab5b-89351e3c64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus.layers[\"counts\"].A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab00825-ad84-4912-a1b9-73a18bc2d43b",
   "metadata": {},
   "source": [
    "We can visualise the data set using PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb26e27-380c-4335-8ebd-bd15bae0d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(lupus)\n",
    "sc.pl.pca(lupus, color=\"cell_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e9888-9656-4b08-836e-b8d80350480b",
   "metadata": {},
   "source": [
    "We can also use UMAP for visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f04ff3-939c-498b-8d47-16670f292b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(lupus)\n",
    "sc.tl.umap(lupus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14264094-eb36-486d-9e7b-4acb7a66f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(lupus, color=\"cell_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da840b33-c7d5-46b5-a5ae-1744c635768d",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ac897-af01-4b2a-aa74-bfda0c49e404",
   "metadata": {},
   "source": [
    "Try using different cell annotations (see the `obs` annotation names above) for the PCA and UMAP plots using the `color` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14f42c-917b-49fc-b966-9da42a636e68",
   "metadata": {},
   "source": [
    "## Variational autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e2790-bf22-4efa-a77d-b1990aab6100",
   "metadata": {},
   "source": [
    "First hyperparameters are set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f86cc-7adc-4f8d-a054-3105c43040ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SIZE = lupus.n_vars\n",
    "HIDDEN_SIZES = [200, 200]\n",
    "LATENT_SIZE = 50\n",
    "LIKELIHOOD_NAME = \"negative_binomial\"\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27954413-ed26-41ee-aa35-504cbc18aa10",
   "metadata": {},
   "source": [
    "Here:\n",
    "\n",
    "* The feature size is the number of genes in the data set.\n",
    "* The hidden sizes are the number of units in each layer of the neural networks\n",
    "* The latent size is the dimension of the latent representation.\n",
    "* The likelihood name is distribution we think the counts follow (other possible options are `poisson`, `zero_inflated_poisson`, and `zero_inflated_negative_binomial`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc250af-1757-4319-8ee0-e244f88849f0",
   "metadata": {},
   "source": [
    "The VAE model is then initialised and compiled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eaaccd-1712-4785-ba7a-96a40441d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = scvae.models.VariationalAutoEncoder(\n",
    "    original_dim=FEATURE_SIZE,\n",
    "    intermediate_dims=HIDDEN_SIZES,\n",
    "    latent_dim=LATENT_SIZE,\n",
    "    likelihood_name=LIKELIHOOD_NAME)\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "vae.compile(optimizer=optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba3623d-9b6a-41d6-91c3-34c41ab64275",
   "metadata": {},
   "source": [
    "Now, the VAE model can be trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1490e50-6f3c-4524-b543-028443afcb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_history = vae.fit(lupus, layer=\"counts\", epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de0469-362c-4bf6-9b66-8a02970abeff",
   "metadata": {},
   "source": [
    "The model outputs a [lower bound of the marginal log-likelihood](https://en.wikipedia.org/wiki/Evidence_lower_bound), which is the difference between the reconstruction error and the [KL divergence](https://en.wikipedia.org/wiki/Kullback–Leibler_divergence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b31966-360f-4eba-b0ef-2b66a7e20157",
   "metadata": {},
   "source": [
    "To see if the model has been trained for long enough, we can plot the metrics against the epochs (learning curves):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552cf28-12d4-47c0-a912-f14eb90f9e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvae.visualisation.plot_learning_curves(vae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b233ae-38bd-4939-b3ca-11b954f8a232",
   "metadata": {},
   "source": [
    "If the learning curves are flattening out, the model has been trained for long enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c889e-9f7b-4d3a-9eb3-52216e3a610a",
   "metadata": {},
   "source": [
    "The model can be evaluated on the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd252aab-111d-46e0-bcb6-98c5ae176cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_evaluation = vae.evaluate(lupus, layer=\"counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251806a1-3fe3-4bf7-9f41-803d8156f5e5",
   "metadata": {},
   "source": [
    "To visualise the latent representation, we can map the data set to the latent space using the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5caef-1761-491f-a50d-73d9da1b9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_latent_representation = ad.AnnData(\n",
    "    vae.encoder.predict(lupus, layer=\"counts\"),\n",
    "    obs=lupus.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857ed8e-cc1b-416a-9569-d10e38b18d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvae.visualisation.plot_latent_representation(\n",
    "    vae_latent_representation, annotation_name=\"cell_type\", model=vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e4318-43d9-4f87-92b7-b1d812e23a6c",
   "metadata": {},
   "source": [
    "Here, the black ellipse shows the prior distribution of the latent representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f5d21-23fe-4d4f-94b2-d756c8b485a7",
   "metadata": {},
   "source": [
    "We can also plot the latent representation using UMAP, but since this method does not generalise (see [transduction](https://en.wikipedia.org/wiki/Transduction_(machine_learning)), we cannot plot the prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137f182-8f49-44c7-9224-06d8084d3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(vae_latent_representation)\n",
    "sc.tl.umap(vae_latent_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70dbb2-816a-426f-b023-295d3b216f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(vae_latent_representation, color=\"cell_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e3253-c64e-4290-9080-4578c2e717ba",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf2ff4-d4b1-4f71-8182-2e34f27070a4",
   "metadata": {},
   "source": [
    "* Try training the model with different hyperparameters and compare the log-likelihood lower bounds.\n",
    "* Visualise the latent representation using different cell annotations.\n",
    "* Compare with the PCA and UMAP plots of the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd714e-b355-4e6a-a492-a88b341dc6fb",
   "metadata": {},
   "source": [
    "## Gaussian-mixture VAE (GMVAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b195d-643e-4a3b-a525-8ca2d73b9407",
   "metadata": {},
   "source": [
    "The Gaussian-mixture VAE uses multiple Gaussian components to model the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1665b2f-606d-4382-86ce-b96487db2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPONENT_COUNT = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce35ab-d09e-4622-872b-afe5e7d13e07",
   "metadata": {},
   "source": [
    "Initialise, compile, and train a GMVAE model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c460a-428c-444e-9f85-f449ea42ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmvae = scvae.models.VariationalAutoEncoder(\n",
    "    original_dim=FEATURE_SIZE,\n",
    "    intermediate_dims=HIDDEN_SIZES,\n",
    "    latent_dim=LATENT_SIZE,\n",
    "    likelihood_name=LIKELIHOOD_NAME,\n",
    "    approximate_posterior_name=\"gaussian_mixture\",\n",
    "    prior_name=\"gaussian_mixture\",\n",
    "    mixture_component_size=COMPONENT_COUNT)\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "gmvae.compile(optimizer=optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5861a44-6cf8-43fa-9a83-c3297f4d2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmvae_history = gmvae.fit(lupus, layer=\"counts\", epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1639b4-e61d-4311-8854-71dc66afa74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvae.visualisation.plot_learning_curves(gmvae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6a357-51e2-4d2f-bd22-2ddbfdd8ecdb",
   "metadata": {},
   "source": [
    "Evaluate the GMVAE model and visualise the latent representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce04882-a508-4a82-a547-d08dfbbf5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmvae_evaluation = gmvae.evaluate(lupus, layer=\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a64dd1-c5c3-4069-bacd-1d62b290ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmvae_latent_values, gmvae_latent_category_logits = gmvae.encoder.predict(\n",
    "    lupus, layer=\"counts\")\n",
    "gmvae_latent_representation = ad.AnnData(\n",
    "    gmvae_latent_values,\n",
    "    obs=lupus.obs)\n",
    "gmvae_latent_representation.obs[\"latent_category\"] = (\n",
    "    gmvae_latent_category_logits.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11e3f0-4a31-4abd-9a92-68721acd53f4",
   "metadata": {},
   "source": [
    "PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06eba2-a38b-41d6-a6d6-19fe643e8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "scvae.visualisation.plot_latent_representation(\n",
    "    gmvae_latent_representation, annotation_name=\"cell_type\", model=gmvae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c04de-a722-4fd0-b20e-25cbe2cc121e",
   "metadata": {},
   "source": [
    "The ellipses show the individual Gaussian components, and the plot to the right shows their corresponding contribution to the total distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc184b8-c6ca-433a-8106-aaee64208b10",
   "metadata": {},
   "source": [
    "UMAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9738c8b-ee99-436d-917c-dad4b14ba695",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(gmvae_latent_representation)\n",
    "sc.tl.umap(gmvae_latent_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c60be-8f61-4641-92f0-9281f42bc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(gmvae_latent_representation, color=\"cell_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73ebc7-1240-4380-90a9-4876e18b6a46",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b9365-1d08-4bd3-ba6a-c7dd436a2260",
   "metadata": {},
   "source": [
    "* Try training the model with different hyperparameters and compare the log-likelihood lower bounds.\n",
    "* Visualise the latent representation using different cell annotations.\n",
    "* Compare with the PCA and UMAP plots of the original data set and the VAE latent representation.\n",
    "* Compare the log-likelihood lower bound with the one for the VAE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
